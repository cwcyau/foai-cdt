# Fundamentals of AI 2

This is a two week module designed to provide a rapid introduction to key or under-studied topics in artificial intelligence. 

In 2025/26, this will include:

## Bayesian Uncertainty Quantification. Int: Rainforth, Teh.

Uncertainty quantification is a fundamental pillar of trustworthy and robust AI. Bayesian statistics plays a central role in this effort, providing a principled framework for modeling uncertainty and making probabilistic predictions. Students will explore both classical and modern Bayesian approaches for representing uncertainty in machine learning, including Bayesian Neural Networks, Variational Inference, and Deep Ensembles. In addition, the module covers methods such as Active Learning and Bayesian Experimental Design, alongside algorithms like Thompson
Sampling and Bootstrapped Bandits that blend uncertainty estimation with exploration in sequential decision-making.

## Statistical Wrappers for Black-Box ML Methods. Int: Caron, Patrick Rebeschini.

Students will study statistical wrappers that enhance black-box machine learning models with formal inference guarantees. Frequentist statistics plays a key role in this domain, offering robust tools for deriving valid conclusions without relying on prior distributions. Topics include
Double ML, Prediction-Powered Inference, and Conformal Prediction, as well as Anytime-valid Inference techniques, such as hypothesis testing with p-values, which support ongoing model evaluation and monitoring. Students will explore applications in modern AI systems, including
Large Language Models, where these tools can be used to help detect performance degradation, distributional drift, and emerging biases.

## Deep Generative Modelling. Int: Teh.

Students will gain a comprehensive introduction to deep generative modeling, a central area of AI with wide-ranging applications in vision, language, and the sciences. Students will first revisit foundational probabilistic methods, including latent variable models, Variational Autoencoders (VAEs),ormalizing flows, and Generative Adversarial Networks (GANs). Building on these, the course explores recent advances such as flow matching and denoising diUusion models, which underpin state-of-the-art performance in tasks like image generation and data augmentation, as
well as discussing applications in anomaly detection, time series modeling, and multi-modal learning.
